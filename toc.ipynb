{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we've gathered the data and...\n",
    "    - Joined in any applicable external data sets\n",
    "    - Removed any non-useful columns (requires domain expertise)\n",
    "    - Removed and/or imputed nulls\n",
    "    - Performed any feature engineering (PolynomialFeatures, etc.)\n",
    "        - Faceted plots can help here and other visualizations\n",
    "        - Potentially discretiztion (make numeric into a category 'bin') for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Top down' - starts with the best feature and adds the 'next best' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KBest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification: uses ANOVA F-score\n",
    "        http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target * -1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KBest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE - Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regularization (L1 Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DATA NEEDS X: int or float \n",
    "    DATA NEEDS y: int or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boo():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Easy, interpretable & gives feature weights (.coef_); not tunable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lin regression with fixed regularization (alpha), CAN 'zero' out factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lin regression that searches a list of alphas that you supply, CAN 'zero' out factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lin regression with fixed regularization (alpha), CAN'T 'zero' out factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lin regression that searches a list of alphas, CAN'T 'zero' out factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    hybrid b/w lasso and ridge (fixed l1 ratio mix), searches a list of input alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    hybrid b/w lasso and ridge, grid searches alphas as well as l1 'mix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DATA NEEDS X: int or float \n",
    "    DATA NEEDS y: int (definitely), str (maybe, needs tested) - binary class only, else OvA (one versus all) - not sure if these needs manual label encoded or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    can use L1/L2 penalty, can also tune C parameter (inverse of alpha - so lower C = more smoothing/regularization). Yields a probability of a class in .proba_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Can be used for regression or classification, but usually classification.\n",
    "    \n",
    "    DATA NEEDS X: int or float (b/c we calc dist b/w neighbors, must be scaled) \n",
    "    DATA NEEDS y: int, float, str (anything)\n",
    "\n",
    "    KNN - can change k (number of neighbors), usually b/w 2-10 neighbors, non-parametric so good for high dimensionality (lots of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note: sklearn calls regression SVM's SVR, and classification SVM's SVC.\n",
    "    DATA NEEDS X: int or float \n",
    "    DATA NEEDS y: ints or floats for SVR, int/float/string for SVC \n",
    "\n",
    "    Tuning params:\n",
    "        SVM - C, kernel\n",
    "        linear kernel: just regularization, C\n",
    "        poly kernel: degree (more degrees = more fit/curvy)\n",
    "        rbf kernel: gamma (higher gamma = more fit/curvy)\n",
    "        sigmoid kernel: read the docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonsemble Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees that are not ensemble. Regression OR classification \n",
    "    \n",
    "    DATA NEEDS X: int or float \n",
    "    DATA NEEDS y: ints or floats for SVR, int/float/string for SVC \n",
    "\n",
    "    DTC (classifier)\n",
    "        max_depth: numbers of levels (height of) the tree / splits down a branch, as increase max_depth, model will overfit\n",
    "        min_samples_leaf: lower is more overfit, higher is more underfit (I've found values between 3-7 work well for this)\n",
    "\n",
    "    DTR (regressor) - not covered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note: Ensemble 'containers'\n",
    "    DATA NEEDS X: various, depends on base estimator\n",
    "    DATA NEEDS y: various, depends on base estimator\n",
    "\n",
    "    RandomForest(Regressor/Classifier): randomly sampled regular trees, sampled n_estimator number of times, then 'majority voted' upon. The rest of the tuning is same as the decision tree classifier/regressor.\n",
    "    BaggingRegressor/Classifier: see docs, defaults to DTC/R    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note: Ensemble 'containers'\n",
    "    DATA NEEDS X: various, depends on base estimator\n",
    "    DATA NEEDS y: various, depends on base estimator\n",
    "\n",
    "    AdaBoostClassifier/R: n_estimators, number of subsequent base estimators to build, Defaults to DTC/R\n",
    "    GradientBoostingClassifier/R: n_estimators, number of subsequent base estimators to build. Defaults to DTC/R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "187px",
    "width": "313px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "880px",
    "left": "0px",
    "right": "803px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
