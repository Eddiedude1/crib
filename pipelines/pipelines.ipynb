{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get rid of float conversion warning during standard scaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline()** is to **make_pipeline()** as\n",
    "**FeatureUnion()** is to **make_union()**\n",
    "\n",
    "**Pipelines** stick things on top of each other (one transformer after the prior)\n",
    "\n",
    "**FeatureUnions** stick things next to each other (french fries - the output of the transformer gets stuck NEXT to the prior transformer)\n",
    "\n",
    "Bonus: [FunctionTransformer()](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer) - makes a function into a fit/transform class object\n",
    "    \n",
    "1. **Pipeline():**\n",
    "    * takes a list of tuples\n",
    "    * ('name_of_pipeline_object', Class_that_transforms())\n",
    "2. **make_pipeline():**\n",
    "    * takes a comma-separated list of steps (must be fit/transformable classes)\n",
    "    * returns a pipeline, with each step named the lower-case version of itself, i.e. StandardScaler() becomes 'standardscaler'\n",
    "3. **FeatureUnion():**\n",
    " * take a list of pipelines OR fit/transformable classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the housing data set\n",
    "df = pd.read_csv('./datasets/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers have .fit() and .transform() methods and can be placed into pipeline (up/down) or union (side/side) functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Accepts a single column and returns the column as a numpy array\n",
    "    Richard method\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[[self.column]].values\n",
    "    \n",
    "class FeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Accepts a list of columns and returns the columns as a numpy array\n",
    "    Greg method\n",
    "    FeaturesExtractor(['colHeader1', 'colHeader2']).transform(df)\n",
    "    NOTE: this doens't work, will complain about dissimilar array sizes during .fit() of pipe, see\n",
    "    https://github.com/scikit-learn/scikit-learn/issues/2034    \n",
    "    \"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if len(self.columns) > 1:\n",
    "            return X[self.columns].values\n",
    "        else:\n",
    "            return X[self.columns[0]].values\n",
    "\n",
    "class CategoricalExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    One-hot-encodes a categorical (string) column. Not used in this notebook.\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.values = None\n",
    "        \n",
    "    def _create_values(self, indices):\n",
    "        return {ind: i+1 for i, ind in enumerate(indices)}\n",
    "    \n",
    "    def _apply_values(self, row_val):\n",
    "        return self.values.get(row_val, 0)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.values = self._create_values(X[self.column].value_counts().index)\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        col = X[self.column].apply(self._apply_values)\n",
    "        return col.values.reshape(-1, 1)\n",
    "    \n",
    "class YesNoEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Takes a list of columns and returns Y/N 1/0 encoded df\n",
    "    Example: YesNoEncoder(['Column Name']).transform(df)\n",
    "    Returns a transformed column, if 'Y' then 1, else 0\n",
    "    \"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if len(self.columns) > 1:\n",
    "            return X[self.columns].apply(lambda x: 1 if x == 'Y' else 0).values\n",
    "        else:\n",
    "            return X[self.columns[0]].apply(lambda x: 1 if x == 'Y' else 0).values.reshape(-1, 1)\n",
    "        \n",
    "class MakeFloat(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Takes a column name and returns a float\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.to_numeric(X[self.column], downcast='float')\n",
    "#         return X[self.columns[0]].apply(lambda x: 1 if x == 'Y' else 0).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an 'X' matrix using make_union(), then again using FeatureUnion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_union method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yesnoencoder', YesNoEncoder(columns=['Central Air'])),\n",
       " ('featureextractor-1', FeatureExtractor(column='Lot Area')),\n",
       " ('featureextractor-2', FeatureExtractor(column='Year Built')),\n",
       " ('featureextractor-3', FeatureExtractor(column='Overall Qual'))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform Central Air Y/N to 1/0 and tack on the remaining features on the RIGHT\n",
    "# note that the result of the union is another transformer class object\n",
    "# The labels of the unions are made automatically, i.e. 'yesnoencoder'\n",
    "\n",
    "combine_features_union = make_union(\n",
    "    YesNoEncoder(['Central Air']),\n",
    "    FeatureExtractor('Lot Area'),\n",
    "    FeatureExtractor('Year Built'),\n",
    "    FeatureExtractor('Overall Qual')\n",
    ")\n",
    "\n",
    "# display the union'd array of Central Air and the other factors (like a list of columns)\n",
    "combine_features_union.get_params()['transformer_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureUnion() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yne', YesNoEncoder(columns=['Central Air'])),\n",
       " ('la', FeatureExtractor(column='Lot Area')),\n",
       " ('yb', FeatureExtractor(column='Year Built')),\n",
       " ('oq', FeatureExtractor(column='Overall Qual'))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allows naming of the unions (and weighting of transformers), takes a list of tuples\n",
    "combine_features_union = FeatureUnion([\n",
    "    ('yne', YesNoEncoder(['Central Air'])),\n",
    "    ('la', FeatureExtractor('Lot Area')),\n",
    "    ('yb', FeatureExtractor('Year Built')),\n",
    "    ('oq', FeatureExtractor('Overall Qual'))\n",
    "])\n",
    "\n",
    "# display the union'd array of Central Air and the other factors (like a list of columns)\n",
    "combine_features_union.get_params()['transformer_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No grid search, make_pipeline() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 NAME: featureunion\n",
      " Step 1 TRANSFORMER: FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('yne', YesNoEncoder(columns=['Central Air'])), ('la', FeatureExtractor(column='Lot Area')), ('yb', FeatureExtractor(column='Year Built')), ('oq', FeatureExtractor(column='Overall Qual'))],\n",
      "       transformer_weights=None)\n",
      "\n",
      "Step 2 NAME: standardscaler\n",
      " Step 2 TRANSFORMER: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "\n",
      "Step 3 NAME: randomforestclassifier\n",
      " Step 3 TRANSFORMER: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    combine_features_union,\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "# print out the steps    \n",
    "[print('Step {} NAME: {}\\n Step {} TRANSFORMER: {}\\n'\n",
    "       .format(i+1, step[0], i+1, step[1])) for i, step in enumerate(pipe.steps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No grid search, Pipeline() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 NAME: cfu\n",
      " Step 1 TRANSFORMER: FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('yne', YesNoEncoder(columns=['Central Air'])), ('la', FeatureExtractor(column='Lot Area')), ('yb', FeatureExtractor(column='Year Built')), ('oq', FeatureExtractor(column='Overall Qual'))],\n",
      "       transformer_weights=None)\n",
      "\n",
      "Step 2 NAME: ss\n",
      " Step 2 TRANSFORMER: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "\n",
      "Step 3 NAME: clf\n",
      " Step 3 TRANSFORMER: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the names are different, as we've named them 'cfu' and 'ss'\n",
    "pipe = Pipeline([\n",
    "    ('cfu', combine_features_union),\n",
    "    ('ss', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# print out the steps    \n",
    "[print('Step {} NAME: {}\\n Step {} TRANSFORMER: {}\\n'\n",
    "       .format(i+1, step[0], i+1, step[1])) for i, step in enumerate(pipe.steps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and fit, no grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828956893287\n"
     ]
    }
   ],
   "source": [
    "# drop all but the target y from the df\n",
    "X = df.drop('Sale Condition', axis=1)\n",
    "\n",
    "# select the target y\n",
    "y = df['Sale Condition']\n",
    "\n",
    "# train test split time\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# do 5 fold CV, using the pipeline backend\n",
    "print(cross_val_score(pipe, X_train, y=y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add in grid searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('cfu', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('yne', YesNoEncoder(columns=['Central Air'])), ('la', FeatureExtractor(column='Lot Area')), ('yb', FeatureExtractor(column='Year Built')), ('oq', FeatureExtractor(column='Overall Qual'))],\n",
       "       transformer_weights=None)), ('ss', Stand...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'ss': [StandardScaler(copy=True, with_mean=True, with_std=True)], 'clf_gs': [GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weight...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeGS = Pipeline([\n",
    "    ('cfu', combine_features_union),\n",
    "    ('ss', StandardScaler()),\n",
    "    ('clf_gs', GridSearchCV(RandomForestClassifier(),param_grid={}))\n",
    "])\n",
    "\n",
    "# define the grid search that controls the named pipeline objects\n",
    "grid = {\n",
    "    # clean up the ss\n",
    "    'ss':[StandardScaler()],\n",
    "    'clf_gs':[GridSearchCV(KNeighborsClassifier(),\n",
    "                         param_grid={'n_neighbors':[3,6,9]}),\n",
    "            GridSearchCV(RandomForestClassifier(),\n",
    "                         param_grid={'n_estimators':np.arange(20,120,20),\n",
    "                                     'max_depth':np.arange(5,30,5)})\n",
    "           ]\n",
    "}\n",
    "\n",
    "# create grid search object with above grid searching parameters and fit\n",
    "gs = GridSearchCV(pipeGS,param_grid=grid)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.8668122270742358\n",
      "Testing score: 0.8375184638109305\n",
      "Params of best model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print('Training score: {}\\nTesting score: {}\\nParams of best model: {}'\n",
    "      .format(\n",
    "        gs.score(X_train, y_train), \n",
    "        gs.score(X_test, y_test),\n",
    "        gs.best_estimator_.get_params()['clf_gs'].best_estimator_\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GS for PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'pca__n_components':[1,2,3]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs.fit(X, y)\n",
    "gs.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
